# 简介

本项目基于Python开发，是一个专为气象内容定制的综合爬虫框架，爬取内容覆盖主流媒体，各大论坛及各类相关网络信息源。可提供对爬取内容筛选，分析，整合，展示等功能。框架中将各个功能模块区分开，方便实现子模块，进而便捷地扩展新消息源爬取能力。

本项目将爬虫的各个功能流程区分成Spider模块（主控），Downloader模块（下载器），PageProcesser模块（页面分析），Scheduler模块（任务队列），Storage模块(数据存储）， Analysis(统计)模块,Pipeline模块（结果输出展示）等


# 硬件配置
服务器：浪潮
操作系统：Linux(Ubuntu 14.04)
CPU：Intel 至强E5-2698 16核
内存：64G
硬盘：2T
网络：100M双线接入

# 软件
Python（编程语言）
Redis（消息队列）
Mysql（数据库）
Scrapy（爬虫框架）
Celery（任务队列）
Tornado（数据展示框架）
……

# 技术方案
本项目涉及到爬取的网站数目繁多，网页结构各异。而且诸如百度贴吧、新浪微博等网站有较强的反爬虫机制，过于频繁的抓取数据存在被封号或IP黑名单的风险，将会严重影响数据获取效果。对此，我们在设计时需要代理IP池以应对反爬虫机制，保证项目的正常进行。同时，单服务器长时间大规模的爬取数据，爬取速度及稳定性易受影响。出于性能考虑以及保证项目正常进行，我们设计时采用分布式架构。

## 内容筛选（将关键字载入，判断是否命中，若命中再解析，抓取信息）
本项目所需内容主要涉及气象领域。根据提供的气象领域的关键字（如气候、洪水、天气预报、空气污染及气象专有名词等）将爬取的内容筛选。基于数据量过大，我们需要设计合理地算法以平衡筛选性能与精确度。我们设计时考虑使用与搜索引擎相同地处理流程，将抓取数据汇总后先进行基础过滤、分词，将分词结果与关键字列表进行匹配，若命中则提取信息并存入数据库，并在库中对每个词分别建立倒排索引以提高检索性能。


## 数据库
由于项目将长期运行，数据存储规模大，需要设计合理的存储结构，以便后期、地数据处理分析以及可视化等功能。初步设计地存储结构以及表间关系如下图。
(实体关系模型图)

## 内容展示(使用Tornado框架搭建展示页面）
Tornado是一个使用非阻塞网络I/O的异步Web后端框架，可以支撑上万级的连接，并且Tornado开发简单易编写，作为一个轻量级，可拓展和部署能力都不错，适合承载项目的后台展示功能。

##　框架



Todo 画出

![img](https://camo.githubusercontent.com/a552b7019cbf274fe4cbe5a03c670e072a93978c/687474703a2f2f6f696970357a38396b2e626b742e636c6f7564646e2e636f6d2f576563686174494d47382e6a706567)
##  设计流程

##　数据库结构
Todo 数据库结构图

#数据展示

#准备怎么样做这些事情　
初步计划






宽度搜索，ＵＲＬ分析，去重。
对爬虫的连接网络设计及读取时间。

由于网络信息繁多，我们需要的仅是气象方面的，我们需要从中筛选出需要的信息，避免无用信息。节约大量时间，服务器资源。

#第一阶段
预期时间
##　技术选型
## 数据库设计 
##　框架搭建，
##　新闻爬取，网站分三类，新闻类，论坛类，其它类。根据反爬虫的力度
## Demo页面。

#第二阶段


#第三

文档交付
联调&验收
交付测试
